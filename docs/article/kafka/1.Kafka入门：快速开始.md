---
title: Kafka入门：快速开始
date: 2026-01-15
description: 了解Kafka的基本概念，学习安装和基本操作，开始你的Kafka之旅
---

# Kafka入门：快速开始

## 一、什么是Kafka

Apache Kafka是一个分布式流处理平台，最初由LinkedIn开发，后来成为Apache软件基金会的顶级项目。Kafka被设计用于处理实时数据流，具有高吞吐量、可扩展性和容错性。

### 1.1 Kafka的主要特点

- **高吞吐量**：能够处理每秒数百万条消息
- **可扩展性**：支持水平扩展，可以轻松添加更多Broker
- **持久化存储**：消息持久化到磁盘，支持数据保留策略
- **分布式架构**：天然支持分布式部署
- **容错性**：通过Replication机制保证高可用
- **实时性**：低延迟的消息传递

### 1.2 Kafka的主要用途

1. **消息队列**：作为传统消息队列使用，解耦生产者和消费者
2. **日志收集**：收集各种服务的日志数据
3. **流处理**：实时处理数据流（配合Kafka Streams）
4. **事件溯源**：存储事件流，支持事件溯源模式
5. **指标监控**：收集和传输监控指标数据

### 1.3 Kafka vs 传统消息队列

| 特性 | Kafka | RabbitMQ | RocketMQ |
|------|-------|----------|----------|
| 吞吐量 | 极高 | 中等 | 高 |
| 延迟 | 低 | 低 | 低 |
| 持久化 | 磁盘持久化 | 内存/磁盘 | 磁盘持久化 |
| 消息顺序 | 分区内有序 | 队列有序 | 队列有序 |
| 适用场景 | 大数据流处理 | 传统消息队列 | 电商场景 |

## 二、Kafka核心概念

在深入学习之前，先了解几个核心概念：

- **Topic（主题）**：消息的分类，类似于数据库中的表
- **Partition（分区）**：Topic的物理分区，用于并行处理
- **Producer（生产者）**：发送消息到Topic的客户端
- **Consumer（消费者）**：从Topic读取消息的客户端
- **Broker（代理）**：Kafka服务器节点
- **Consumer Group（消费者组）**：一组消费者共同消费一个Topic

## 三、安装Kafka

### 3.1 系统要求

- **Java**：Kafka需要Java 8或更高版本
- **内存**：至少2GB可用内存
- **磁盘**：足够的磁盘空间存储消息

### 3.2 安装Java

#### Linux/macOS

```bash
# 检查Java版本
java -version

# Ubuntu/Debian安装Java
sudo apt update
sudo apt install openjdk-11-jdk

# CentOS/RHEL安装Java
sudo yum install java-11-openjdk-devel

# macOS使用Homebrew
brew install openjdk@11
```

#### Windows

1. 访问 [Oracle JDK](https://www.oracle.com/java/technologies/downloads/) 或 [OpenJDK](https://adoptium.net/)
2. 下载并安装Java 11或更高版本
3. 配置JAVA_HOME环境变量

### 3.3 下载Kafka

#### 方式一：官方二进制包（推荐）

```bash
# 下载Kafka（以2.13-3.5.0为例）
cd /opt
sudo wget https://downloads.apache.org/kafka/3.5.0/kafka_2.13-3.5.0.tgz

# 解压
sudo tar -xzf kafka_2.13-3.5.0.tgz

# 创建软链接（可选）
sudo ln -s kafka_2.13-3.5.0 kafka

# 设置权限
sudo chown -R $USER:$USER /opt/kafka
```

#### 方式二：使用包管理器

**macOS (Homebrew)**：
```bash
brew install kafka
```

**注意**：Kafka 2.8.0+版本已经内置Zookeeper，不再需要单独安装Zookeeper。

### 3.4 配置环境变量

```bash
# 编辑 ~/.bashrc 或 ~/.zshrc
export KAFKA_HOME=/opt/kafka
export PATH=$PATH:$KAFKA_HOME/bin

# 重新加载配置
source ~/.bashrc  # 或 source ~/.zshrc
```

## 四、启动Kafka

### 4.1 Kafka 2.8.0+（内置Zookeeper）

Kafka 2.8.0+版本使用KRaft模式，不再需要Zookeeper。

```bash
# 启动Kafka（会自动启动内置的Zookeeper）
cd $KAFKA_HOME
bin/kafka-server-start.sh config/kraft/server.properties
```

### 4.2 Kafka 2.8.0以下（需要Zookeeper）

#### 启动Zookeeper

```bash
# 启动Zookeeper
cd $KAFKA_HOME
bin/zookeeper-server-start.sh config/zookeeper.properties
```

#### 启动Kafka

```bash
# 在新的终端窗口启动Kafka
cd $KAFKA_HOME
bin/kafka-server-start.sh config/server.properties
```

### 4.3 后台运行

```bash
# 后台启动Zookeeper（旧版本）
nohup bin/zookeeper-server-start.sh config/zookeeper.properties > zookeeper.log 2>&1 &

# 后台启动Kafka
nohup bin/kafka-server-start.sh config/server.properties > kafka.log 2>&1 &
```

### 4.4 使用systemd（Linux）

创建服务文件：

```bash
# 创建Kafka服务文件
sudo vim /etc/systemd/system/kafka.service
```

内容：

```ini
[Unit]
Description=Apache Kafka Server
After=network.target

[Service]
Type=simple
User=kafka
ExecStart=/opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties
ExecStop=/opt/kafka/bin/kafka-server-stop.sh
Restart=on-failure

[Install]
WantedBy=multi-user.target
```

启动服务：

```bash
sudo systemctl daemon-reload
sudo systemctl start kafka
sudo systemctl enable kafka
```

## 五、基本操作

### 5.1 创建Topic

```bash
# 创建Topic
bin/kafka-topics.sh --create \
  --topic test-topic \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

# 查看Topic列表
bin/kafka-topics.sh --list --bootstrap-server localhost:9092

# 查看Topic详情
bin/kafka-topics.sh --describe \
  --topic test-topic \
  --bootstrap-server localhost:9092
```

### 5.2 发送消息（Producer）

```bash
# 启动Producer，输入消息
bin/kafka-console-producer.sh \
  --topic test-topic \
  --bootstrap-server localhost:9092
```

在终端中输入消息，每行一条，按Enter发送。

### 5.3 消费消息（Consumer）

```bash
# 启动Consumer，消费消息
bin/kafka-console-consumer.sh \
  --topic test-topic \
  --from-beginning \
  --bootstrap-server localhost:9092
```

`--from-beginning`参数表示从Topic的开始位置消费所有消息。

### 5.4 查看Consumer Group

```bash
# 查看Consumer Group列表
bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --list

# 查看Consumer Group详情
bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe \
  --group test-group
```

## 六、验证安装

### 6.1 检查Kafka进程

```bash
# 检查Kafka进程
ps aux | grep kafka

# 检查端口监听
netstat -tlnp | grep 9092
# 或
ss -tlnp | grep 9092
```

### 6.2 测试消息发送和消费

1. **打开第一个终端**，启动Consumer：
   ```bash
   bin/kafka-console-consumer.sh --topic test-topic --from-beginning --bootstrap-server localhost:9092
   ```

2. **打开第二个终端**，启动Producer并发送消息：
   ```bash
   bin/kafka-console-producer.sh --topic test-topic --bootstrap-server localhost:9092
   ```
   然后输入几条消息，如：
   ```
   Hello Kafka
   This is a test message
   Kafka is awesome
   ```

3. **观察第一个终端**，应该能看到刚才发送的消息。

### 6.3 检查日志

```bash
# 查看Kafka日志
tail -f logs/server.log

# 查看Zookeeper日志（旧版本）
tail -f logs/zookeeper.log
```

## 七、常见问题解决

### 7.1 Java版本问题

**问题**：提示Java版本不兼容

**解决方法**：
```bash
# 检查Java版本
java -version

# 设置JAVA_HOME
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
```

### 7.2 端口被占用

**问题**：9092端口被占用

**解决方法**：
```bash
# 查看占用端口的进程
sudo lsof -i :9092
# 或
sudo netstat -tlnp | grep 9092

# 停止占用端口的进程，或修改Kafka配置使用其他端口
```

### 7.3 Zookeeper连接失败（旧版本）

**问题**：Kafka无法连接Zookeeper

**解决方法**：
1. 确保Zookeeper已启动
2. 检查Zookeeper端口（默认2181）是否监听
3. 检查Kafka配置文件中的Zookeeper地址

### 7.4 磁盘空间不足

**问题**：Kafka无法写入消息

**解决方法**：
```bash
# 检查磁盘空间
df -h

# 清理旧日志（谨慎操作）
# 修改log.retention.hours配置，自动清理旧消息
```

## 八、停止Kafka

### 8.1 正常停止

```bash
# 停止Kafka
bin/kafka-server-stop.sh

# 停止Zookeeper（旧版本）
bin/zookeeper-server-stop.sh
```

### 8.2 强制停止

```bash
# 查找Kafka进程
ps aux | grep kafka

# 强制杀死进程
kill -9 <PID>
```

## 九、下一步学习

完成本课后，你应该能够：

- ✅ 理解Kafka的基本概念和用途
- ✅ 在Linux、macOS、Windows上安装Kafka
- ✅ 启动和停止Kafka
- ✅ 创建Topic、发送和消费消息
- ✅ 使用基本命令行工具

接下来可以学习：

1. **第2课：核心概念** - 深入理解Topic、Partition、Consumer Group等概念
2. **第3课：消息生产** - 学习使用Producer API发送消息

## 十、总结

- Kafka是一个分布式流处理平台，具有高吞吐量和可扩展性
- Kafka 2.8.0+版本内置Zookeeper，简化了部署
- 基本操作包括创建Topic、发送消息、消费消息
- 使用命令行工具可以快速验证Kafka功能
- 理解基本概念是深入学习的基础

掌握Kafka的基本操作后，你就可以继续深入学习核心概念了！
